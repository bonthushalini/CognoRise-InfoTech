{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task-3 : DIABETES PREDICTION**"
      ],
      "metadata": {
        "id": "Vud6ibe1TsCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwu-_c_bOQXN",
        "outputId": "060513be-16fb-437b-d79e-4599c4aecd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
            "0  Female  80.0             0              1           never  25.19   \n",
            "1  Female  54.0             0              0         No Info  27.32   \n",
            "2    Male  28.0             0              0           never  27.32   \n",
            "3  Female  36.0             0              0         current  23.45   \n",
            "4    Male  76.0             1              1         current  20.14   \n",
            "\n",
            "   HbA1c_level  blood_glucose_level  diabetes  \n",
            "0          6.6                  140         0  \n",
            "1          6.6                   80         0  \n",
            "2          5.7                  158         0  \n",
            "3          5.0                  155         0  \n",
            "4          4.8                  155         0  \n",
            "Random Forest Classifier Accuracy: 0.97\n",
            "Confusion Matrix:\n",
            "[[18224    68]\n",
            " [  528  1180]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.95      0.69      0.80      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.96      0.84      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "\n",
            "K-Nearest Neighbors Accuracy: 0.96\n",
            "Confusion Matrix:\n",
            "[[18168   124]\n",
            " [  662  1046]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     18292\n",
            "           1       0.89      0.61      0.73      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.93      0.80      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "\n",
            "AdaBoost Classifier Accuracy: 0.97\n",
            "Confusion Matrix:\n",
            "[[18259    33]\n",
            " [  518  1190]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99     18292\n",
            "           1       0.97      0.70      0.81      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.97      0.85      0.90     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "\n",
            "Logistic Regression Accuracy: 0.96\n",
            "Confusion Matrix:\n",
            "[[18126   166]\n",
            " [  654  1054]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     18292\n",
            "           1       0.86      0.62      0.72      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.91      0.80      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "\n",
            "Decision Tree Classifier Accuracy: 0.95\n",
            "Confusion Matrix:\n",
            "[[17797   495]\n",
            " [  443  1265]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97     18292\n",
            "           1       0.72      0.74      0.73      1708\n",
            "\n",
            "    accuracy                           0.95     20000\n",
            "   macro avg       0.85      0.86      0.85     20000\n",
            "weighted avg       0.95      0.95      0.95     20000\n",
            "\n",
            "\n",
            "The prediction for the example input is: Diabetes\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "df = pd.read_csv('/content/diabetes_prediction_dataset.csv')\n",
        "print(df.head())\n",
        "\n",
        "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']]  # Features\n",
        "y = df['diabetes']\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level']),\n",
        "        ('cat', OneHotEncoder(drop='first'), ['gender', 'smoking_history'])\n",
        "    ])\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "models = {\n",
        "    'Random Forest Classifier': Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                                ('classifier', RandomForestClassifier())]),\n",
        "    'K-Nearest Neighbors': Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                           ('classifier', KNeighborsClassifier())]),\n",
        "    'AdaBoost Classifier': Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                           ('classifier', AdaBoostClassifier())]),\n",
        "    'Logistic Regression': Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                           ('classifier', LogisticRegression(max_iter=1000))]),\n",
        "    'Decision Tree Classifier': Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                                ('classifier', DecisionTreeClassifier())])\n",
        "}\n",
        "\n",
        "#Train the models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'{name} Accuracy: {accuracy:.2f}')\n",
        "    print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n')\n",
        "    print(f'Classification Report:\\n{classification_report(y_test, y_pred)}\\n')\n",
        "\n",
        "def predict_diabetes(input_data, model):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "    prediction = model.predict(input_df)\n",
        "    return 'Diabetes' if prediction[0] == 1 else 'No Diabetes'\n",
        "\n",
        "#Example\n",
        "example_input = ['Male',67, 0, 1, 'not current', 27.32, 6.5, 200]\n",
        "best_model = models['Random Forest Classifier']\n",
        "result = predict_diabetes(example_input, best_model)\n",
        "print(f'The prediction for the example input is: {result}')\n"
      ]
    }
  ]
}
